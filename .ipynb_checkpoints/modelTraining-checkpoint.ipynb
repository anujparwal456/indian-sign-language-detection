{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The provided input folder \"C:/Users/crite/Downloads/Final_Sign_Dataset\" does not exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m input_folder = \u001b[33m\"\u001b[39m\u001b[33mC:/Users/crite/Downloads/Final_Sign_Dataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m output_folder = \u001b[33m\"\u001b[39m\u001b[33mpreprocessed_alphaDigi_dataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43msplitfolders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmove\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Step 2: Create Data Generators with Preprocessing\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Training generator with more aggressive augmentation (within reason for sign language)\u001b[39;00m\n\u001b[32m     30\u001b[39m train_datagen = ImageDataGenerator(\n\u001b[32m     31\u001b[39m     rescale=\u001b[32m1.\u001b[39m/\u001b[32m255\u001b[39m,\n\u001b[32m     32\u001b[39m     rotation_range=\u001b[32m15\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     cval=\u001b[32m0\u001b[39m                      \u001b[38;5;66;03m# Fill with black (often better than white for CNNs)\u001b[39;00m\n\u001b[32m     41\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\splitfolders\\split.py:81\u001b[39m, in \u001b[36mratio\u001b[39m\u001b[34m(input, output, seed, ratio, group_prefix, move)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ratio) \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m):\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`ratio` should\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[43mcheck_input_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_tqdm:\n\u001b[32m     84\u001b[39m     prog_bar = tqdm(desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCopying files\u001b[39m\u001b[33m\"\u001b[39m, unit=\u001b[33m\"\u001b[39m\u001b[33m files\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\splitfolders\\split.py:56\u001b[39m, in \u001b[36mcheck_input_format\u001b[39m\u001b[34m(input)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p_input.is_absolute():\n\u001b[32m     55\u001b[39m         err_msg += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Your relative path cannot be found from the current working directory \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath.cwd()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p_input.is_dir():\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe provided input folder \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is not a directory\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The provided input folder \"C:/Users/crite/Downloads/Final_Sign_Dataset\" does not exists."
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Dataset Preprocessing and Splitting (No changes needed here unless your folder structure is different)\n",
    "# --------------------------------------------\n",
    "input_folder = \"C:/Users/crite/Downloads/Final_Sign_Dataset\"\n",
    "output_folder = \"preprocessed_alphaDigi_dataset\"\n",
    "splitfolders.ratio(\n",
    "    input_folder,\n",
    "    output=output_folder,\n",
    "    seed=42,\n",
    "    ratio=(0.6, 0.2, 0.2),\n",
    "    group_prefix=None,\n",
    "    move=False\n",
    ")\n",
    "\n",
    "# Step 2: Create Data Generators with Preprocessing\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Training generator with more aggressive augmentation (within reason for sign language)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,  # Add horizontal shift\n",
    "    height_shift_range=0.05, # Add vertical shift\n",
    "    zoom_range=0.05,\n",
    "    shear_range=0.03,        # Add shear\n",
    "    horizontal_flip=False,\n",
    "    brightness_range=[0.6, 1.4], # More variation in brightness\n",
    "    fill_mode='constant',\n",
    "    cval=0                      # Fill with black (often better than white for CNNs)\n",
    ")\n",
    "\n",
    "# Validation and Test generators (only rescaling)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Common parameters\n",
    "target_size = (128, 128)\n",
    "color_mode = 'rgb'  # Experiment with RGB - might capture more subtle features\n",
    "batch_size = 32\n",
    "class_mode = 'categorical'\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_folder, 'train'),\n",
    "    target_size=target_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    os.path.join(output_folder, 'val'),\n",
    "    target_size=target_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=False # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    os.path.join(output_folder, 'test'),\n",
    "    target_size=target_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=False # Important for accurate evaluation\n",
    ")\n",
    "\n",
    "# Step 3: Improved Model Building\n",
    "# ----------------------\n",
    "\n",
    "print(\"training\")\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'), \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Use a smaller learning rate initially and add ReduceLROnPlateau\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Training with Enhanced Callbacks\n",
    "# ------------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1) # Increased patience\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1) # Reduce LR if val_loss plateaus\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20, # Increased epochs - early stopping will handle overtraining\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# Step 5: Final Evaluation\n",
    "# ------------------------\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.2%}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('sign_language_alphaDigi_model.h5')\n",
    "\n",
    "# Optional: Visualize Preprocessing\n",
    "# ---------------------------------\n",
    "def visualize_augmentations(generator, num_images=5):\n",
    "    x, y = generator.next()\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(x[i].squeeze())\n",
    "        plt.title(f\"Label: {list(generator.class_indices.keys())[np.argmax(y[i])]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTraining samples (with augmentation):\")\n",
    "visualize_augmentations(train_generator)\n",
    "\n",
    "print(\"\\nValidation samples (no augmentation):\")\n",
    "visualize_augmentations(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
